{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#首先从elasticsearch中选取提取符合条件的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elasticsearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4aea5dbe916e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0melasticsearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0melasticsearch_dsl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0melasticsearch_dsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconnections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0melasticsearch_dsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'elasticsearch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import elasticsearch\n",
    "from elasticsearch_dsl import DocType\n",
    "from elasticsearch_dsl.connections import connections\n",
    "from elasticsearch_dsl.query import *\n",
    " \n",
    "es = elasticsearch.Elasticsearch(\"192.168.*.*:8888\", time_out=30)\n",
    "connections.add_connection('default', es)\n",
    " \n",
    "    \n",
    "start = '2018-07-25T00:00:00'\n",
    "end = '2018-08-03T23:59:59'\n",
    "query1 = {\n",
    "        '_source':\n",
    "            {\n",
    "                'include':['*','*','*'] \n",
    "            },\n",
    "        'query':\n",
    "            {\n",
    "                'bool':{\n",
    "                    'must':[{\n",
    "                        'range':{\n",
    "                            'begin':{\n",
    "                                \"gte\": start,\n",
    "                                \"lte\": end\n",
    "                            }    \n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        'exists':{\n",
    "                            'field':'label'\n",
    "                        }\n",
    "                    }]\n",
    "                }\n",
    "            }                \n",
    "        }\n",
    "res = es.search(index='*', doc_type='*',size = 3000, body=query1)['hits']['hits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将是字符串类型的数据映射成数字   \n",
    "Q：简单的映射为0，1，2，3可行吗？   \n",
    "Q：既然能映射成0，1，2，3，为什么不能映射成0，100，200，300？这两种映射方案会影响后来的决策结果吗？   \n",
    "eg：假设说有一个字段rca，它的取值为‘connection normal’，‘Auth cost ***’，‘dhcp cost ***’，other,...,将其映射为0，1，2，3或者是映射为0，100，200，300，最后的决策结果是一样的吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = []\n",
    "for i in range(len(res)):\n",
    "    data.append(res[i]['_source'])\n",
    "df = pd.DataFrame(data)\n",
    "df['rca_num']= df.rca.apply(lambda x: 0 if x=='connection normal' \n",
    "                            else 1 if re.match( r\"Auth cost\", x,flags=0) is not None\n",
    "                            else 2 if re.match( r\"dhcp cost\", x,flags=0) is not None \n",
    "                            else 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用one-hot编码，处理特征值为字符串的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3e36ece5dcfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mone_hot_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mone_hot_feature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# or X = df.drop['*','*']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# X_train=X_train.values.astype(float)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# y_train=y_train.values.astype(float)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "one_hot_feature = ['*','*']\n",
    "X = df[one_hot_feature] # or X = df.drop['*','*']\n",
    "y = df['label_num']\n",
    "# X_train=X_train.values.astype(float)\n",
    "# y_train=y_train.values.astype(float)\n",
    "# X_test = X_test.values.astype(float)\n",
    "# y_test=y_test.values.astype(float)\n",
    "features = X.columns.tolist() #得到特征值\n",
    "mylabel = df['label_num']\n",
    "targets = list(set(mylabel.tolist())) # 得到类别名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(X) \n",
    "X_encode = enc.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "demean,PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV得到最佳参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看训练结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test,y_predict,target_names=target_names)# precision, recall, f1_score\n",
    "print report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "混淆矩阵，学习曲线的绘制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对特征的重要性进行排序，选择比较重要的特征再进行训练，看看训练结果如何"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBDT\n",
    "feature_index=sorted(enumerate(GraBoostClf.feature_importances_), key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "绘制带有网格线的重要性曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "spacing = 1 # This can be your user specified spacing. \n",
    "minorLocator = MultipleLocator(spacing)\n",
    "ax1.plot(np.arange(1,len(feature_index)+1),\n",
    "         [np.sum(sort_gbdt_fea [:i]) for i in range(1,len(feature_index)+1)])\n",
    "# Set minor tick locations.\n",
    "ax1.yaxis.set_minor_locator(minorLocator)\n",
    "ax1.xaxis.set_minor_locator(minorLocator)\n",
    "# Set grid to use minor tick locations. \n",
    "ax1.grid(which = 'minor',linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选取重要特征，组成新的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.loc[:,new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF，用oob_score, 但是我们不知道测试数据集到底是哪些，编写函数实现，但貌似不对\n",
    "from sklearn.utils import check_random_state,check_array\n",
    "# X1 = check_array(X1, accept_sparse=\"csc\", dtype=DTYPE)\n",
    "# y = check_array(y, accept_sparse='csc', ensure_2d=False, dtype=None)\n",
    "def generate_sample_indices(random_state, n_samples):\n",
    "    \"\"\"Private function used to _parallel_build_trees function.\"\"\"\n",
    "    random_instance = check_random_state(random_state)\n",
    "    sample_indices = random_instance.randint(0, n_samples, n_samples)\n",
    " \n",
    "    return sample_indices\n",
    " \n",
    " \n",
    "def generate_unsampled_indices(random_state, n_samples):\n",
    "    \"\"\"Private function used to forest._set_oob_score function.\"\"\"\n",
    "    sample_indices = generate_sample_indices(random_state, n_samples)\n",
    "    sample_counts = np.bincount(sample_indices, minlength=n_samples)\n",
    "    unsampled_mask = sample_counts == 0\n",
    "    indices_range = np.arange(n_samples)\n",
    "    unsampled_indices = indices_range[unsampled_mask]\n",
    " \n",
    "    return unsampled_indices\n",
    "unsampled_indices = generate_unsampled_indices(666, 2000)#666=RF中参数random_state\n",
    "len(unsampled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制曲线，report 中为str 类型，不知道怎么取出来,所以就自己编写tpr，fpr，recall，precision函数\n",
    "def tpr(y_true,y_pred, label):\n",
    "    '''\n",
    "    pos_label 此时必须是从1开始的int类型\n",
    "    '''\n",
    "    my_cmp = confusion_matrix(y_true, y_pred)\n",
    "    index = [_ for _ in range(len(my_cmp))]\n",
    "    my_tprs = []\n",
    "    for pos_label in label:\n",
    "        index_tmp = index[:]\n",
    "        index_tmp.pop(pos_label-1)     \n",
    "        fn = np.sum(my_cmp[pos_label-1][index_tmp])\n",
    "        tp = my_cmp[pos_label-1][pos_label-1]\n",
    "        try:\n",
    "            my_tpr = float(tp) / (fn+tp)\n",
    "        except:\n",
    "            my_tpr = 0\n",
    "        my_tprs.append(my_tpr)\n",
    "    return my_tprs\n",
    "    \n",
    "        \n",
    "def fpr(y_true,y_pred, label):\n",
    "    myconfusion_matrix = confusion_matrix(y_true, y_pred)\n",
    "    index = [_ for _ in range(len(myconfusion_matrix))]\n",
    "    my_fprs = []\n",
    "    for pos_label in label:\n",
    "        index_tmp = index[:]\n",
    "        index_tmp.pop(pos_label-1)\n",
    "        cmp_tmp = myconfusion_matrix[index_tmp]\n",
    "        cmp_tmp1 = cmp_tmp[:,index_tmp]\n",
    "        tn = np.sum(cmp_tmp1)\n",
    "        cmp_tmp2 = myconfusion_matrix[:,pos_label-1]\n",
    "        cmp_tmp3 = cmp_tmp2[index_tmp]\n",
    "        fp = np.sum(cmp_tmp3)\n",
    "        try:\n",
    "            my_fpr = float(fp) / (tn+fp)\n",
    "        except:\n",
    "            my_fpr = 0\n",
    "        my_fprs.append(my_fpr)\n",
    "    return my_fprs\n",
    "def myrecall(y_true, y_pred, label):\n",
    "    my_cmp = confusion_matrix(y_true, y_pred)\n",
    "    index = [_ for _ in range(len(my_cmp))]\n",
    "    my_recalls = []\n",
    "    for pos_label in label:\n",
    "        index_tmp = index[:]\n",
    "        index_tmp.pop(pos_label - 1)\n",
    "        fn = np.sum(my_cmp[pos_label - 1][index_tmp])\n",
    "        tp = my_cmp[pos_label - 1][pos_label - 1]\n",
    "        try:\n",
    "            my_recall = float(tp) / (fn + tp)\n",
    "        except:\n",
    "            my_recall = 0\n",
    "        my_recalls.append(my_recall)\n",
    "    return my_recalls\n",
    " \n",
    "def myprecision(y_true, y_pred, label):\n",
    "    my_cmp = confusion_matrix(y_true, y_pred)\n",
    "    index = [_ for _ in range(len(cmp))]\n",
    "    my_precisions = []\n",
    "    for pos_label in label:\n",
    "        tp = my_cmp[pos_label - 1][pos_label - 1]\n",
    "        index_tmp = index[:]\n",
    "        index_tmp.pop(pos_label - 1)\n",
    "        cmp_tmp1 = my_cmp[:,pos_label - 1]\n",
    "        cmp_tmp2 = cmp_tmp1[index_tmp]\n",
    "        fp = np.sum(cmp_tmp2)\n",
    "        try:\n",
    "            my_precision = float(tp) / (tp + fp)\n",
    "        except:\n",
    "            my_precision = 0\n",
    "        my_precisions.append(my_precision)\n",
    "    return my_precisions\n",
    " \n",
    "# f1_score = 2 / [(1/precision) + (1/recall)],\n",
    "def myf1_score(y_true, y_pred, label):\n",
    "    my_precisions = myprecision(y_true, y_pred, label)\n",
    "    my_recalls = myrecall(y_true, y_pred, label)\n",
    "    precision_reciprocal = [1/x for x in my_precisions]\n",
    "    recalls_reciprocal = [1/x for x in my_recalls]\n",
    "    temp = [precision_reciprocal[_] + recalls_reciprocal[_] for _ in range(len(precision_reciprocal))]\n",
    "    myf1_scores = [2/_ for _ in temp]\n",
    "    return myf1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树的绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘决策树\n",
    "from sklearn import tree\n",
    "from IPython.display import display, Image\n",
    "dot_data=tree.export_graphviz(dt_clf2,out_file=None,\n",
    "                    feature_names=select_features,\n",
    "                    class_names=class_names,\n",
    "                    filled=True,rounded=True,\n",
    "                    special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "display(Image(graph.create_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
